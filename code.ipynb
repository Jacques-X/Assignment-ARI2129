{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c9b209",
   "metadata": {},
   "source": [
    "# 2. Frame Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53cc4e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames had already been extracted, skipping...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_dir, frame_rate=1):\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not video.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "    \n",
    "    print(f\"Video FPS: {fps}\")\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    print(f\"Duration: {duration:.2f} seconds\")\n",
    "    \n",
    "    # Initialize frame counter\n",
    "    count = 0\n",
    "    frame_count = 0\n",
    "    \n",
    "    # Read until video is completed\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        # Break the loop if we have reached the end of the video\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Save frame at the specified interval\n",
    "        if count % 1 == 0:\n",
    "            frame_filename = os.path.join(output_dir, f\"frame_{frame_count:04d}.jpg\")\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            print(f\"Extracted: {frame_filename}\")\n",
    "            frame_count += 1\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    # Release the video capture object\n",
    "    video.release()\n",
    "    \n",
    "    print(f\"Extraction complete. {frame_count} frames extracted to {output_dir}\")\n",
    "\n",
    "def get_file_paths():\n",
    "    file_paths = []\n",
    "\n",
    "    for root, dirs, files in os.walk(\"videos\"):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path)\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "if not os.path.isdir('frames'): # If it exists, it was done already so do not run\n",
    "    file_paths = get_file_paths()\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        extract_frames(file_path, os.path.join(\"frames\", os.path.basename(file_path)))\n",
    "else :\n",
    "    print(\"Frames had already been extracted, skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6606cc",
   "metadata": {},
   "source": [
    "# 3. Feature Detection and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4367854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - - ORB - -\n",
      "Vid1.mp4/frame_0000.jpg: 976 keypoints in 0.0065s\n",
      "Vid1.mp4/frame_0001.jpg: 977 keypoints in 0.0059s\n",
      "Vid1.mp4/frame_0002.jpg: 976 keypoints in 0.0060s\n",
      "Vid1.mp4/frame_0003.jpg: 976 keypoints in 0.0057s\n",
      "Vid1.mp4/frame_0004.jpg: 977 keypoints in 0.0055s\n",
      "Vid1.mp4/frame_0005.jpg: 983 keypoints in 0.0056s\n",
      "Vid1.mp4/frame_0006.jpg: 985 keypoints in 0.0060s\n",
      "Vid1.mp4/frame_0007.jpg: 985 keypoints in 0.0056s\n",
      "Vid1.mp4/frame_0008.jpg: 980 keypoints in 0.0059s\n",
      "Vid1.mp4/frame_0009.jpg: 980 keypoints in 0.0060s\n",
      "Vid2.mp4/frame_0000.jpg: 947 keypoints in 0.0054s\n",
      "Vid2.mp4/frame_0001.jpg: 954 keypoints in 0.0056s\n",
      "Vid2.mp4/frame_0002.jpg: 948 keypoints in 0.0057s\n",
      "Vid2.mp4/frame_0003.jpg: 957 keypoints in 0.0055s\n",
      "Vid2.mp4/frame_0004.jpg: 952 keypoints in 0.0060s\n",
      "Vid2.mp4/frame_0005.jpg: 960 keypoints in 0.0056s\n",
      "Vid2.mp4/frame_0006.jpg: 951 keypoints in 0.0057s\n",
      "Vid2.mp4/frame_0007.jpg: 946 keypoints in 0.0061s\n",
      "Vid2.mp4/frame_0008.jpg: 949 keypoints in 0.0055s\n",
      "Vid2.mp4/frame_0009.jpg: 953 keypoints in 0.0071s\n",
      "Vid3.mp4/frame_0000.jpg: 944 keypoints in 0.0070s\n",
      "Vid3.mp4/frame_0001.jpg: 941 keypoints in 0.0089s\n",
      "Vid3.mp4/frame_0002.jpg: 940 keypoints in 0.0075s\n",
      "Vid3.mp4/frame_0003.jpg: 945 keypoints in 0.0062s\n",
      "Vid3.mp4/frame_0004.jpg: 951 keypoints in 0.0070s\n",
      "Vid3.mp4/frame_0005.jpg: 951 keypoints in 0.0064s\n",
      "Vid3.mp4/frame_0006.jpg: 956 keypoints in 0.0062s\n",
      "Vid3.mp4/frame_0007.jpg: 948 keypoints in 0.0068s\n",
      "Vid3.mp4/frame_0008.jpg: 950 keypoints in 0.0065s\n",
      "Vid3.mp4/frame_0009.jpg: 948 keypoints in 0.0066s\n",
      "Vid4.mp4/frame_0000.jpg: 1000 keypoints in 0.0069s\n",
      "Vid4.mp4/frame_0001.jpg: 994 keypoints in 0.0068s\n",
      "Vid4.mp4/frame_0002.jpg: 995 keypoints in 0.0076s\n",
      "Vid4.mp4/frame_0003.jpg: 995 keypoints in 0.0067s\n",
      "Vid4.mp4/frame_0004.jpg: 1000 keypoints in 0.0069s\n",
      "Vid4.mp4/frame_0005.jpg: 1000 keypoints in 0.0069s\n",
      "Vid4.mp4/frame_0006.jpg: 1000 keypoints in 0.0071s\n",
      "Vid4.mp4/frame_0007.jpg: 1000 keypoints in 0.0068s\n",
      "Vid4.mp4/frame_0008.jpg: 994 keypoints in 0.0069s\n",
      "Vid4.mp4/frame_0009.jpg: 995 keypoints in 0.0071s\n",
      "Vid5.mp4/frame_0000.jpg: 978 keypoints in 0.0061s\n",
      "Vid5.mp4/frame_0001.jpg: 975 keypoints in 0.0060s\n",
      "Vid5.mp4/frame_0002.jpg: 972 keypoints in 0.0062s\n",
      "Vid5.mp4/frame_0003.jpg: 976 keypoints in 0.0064s\n",
      "Vid5.mp4/frame_0004.jpg: 979 keypoints in 0.0067s\n",
      "Vid5.mp4/frame_0005.jpg: 978 keypoints in 0.0065s\n",
      "Vid5.mp4/frame_0006.jpg: 986 keypoints in 0.0060s\n",
      "Vid5.mp4/frame_0007.jpg: 983 keypoints in 0.0060s\n",
      "Vid5.mp4/frame_0008.jpg: 976 keypoints in 0.0063s\n",
      "Vid5.mp4/frame_0009.jpg: 984 keypoints in 0.0070s\n",
      "Average keypoints: 970.92 | Average Time: 0.01s\n",
      "\n",
      " - - SIFT - -\n",
      "Vid1.mp4/frame_0000.jpg: 312 keypoints in 0.0620s\n",
      "Vid1.mp4/frame_0001.jpg: 321 keypoints in 0.0598s\n",
      "Vid1.mp4/frame_0002.jpg: 337 keypoints in 0.1170s\n",
      "Vid1.mp4/frame_0003.jpg: 363 keypoints in 0.0668s\n",
      "Vid1.mp4/frame_0004.jpg: 368 keypoints in 0.0605s\n",
      "Vid1.mp4/frame_0005.jpg: 381 keypoints in 0.0875s\n",
      "Vid1.mp4/frame_0006.jpg: 382 keypoints in 0.5094s\n",
      "Vid1.mp4/frame_0007.jpg: 334 keypoints in 0.1154s\n",
      "Vid1.mp4/frame_0008.jpg: 354 keypoints in 0.0638s\n",
      "Vid1.mp4/frame_0009.jpg: 369 keypoints in 0.0661s\n",
      "Vid2.mp4/frame_0000.jpg: 214 keypoints in 0.0554s\n",
      "Vid2.mp4/frame_0001.jpg: 217 keypoints in 0.0591s\n",
      "Vid2.mp4/frame_0002.jpg: 219 keypoints in 0.0435s\n",
      "Vid2.mp4/frame_0003.jpg: 221 keypoints in 0.0490s\n",
      "Vid2.mp4/frame_0004.jpg: 214 keypoints in 0.0559s\n",
      "Vid2.mp4/frame_0005.jpg: 199 keypoints in 0.0549s\n",
      "Vid2.mp4/frame_0006.jpg: 239 keypoints in 0.0588s\n",
      "Vid2.mp4/frame_0007.jpg: 214 keypoints in 0.0667s\n",
      "Vid2.mp4/frame_0008.jpg: 210 keypoints in 0.0532s\n",
      "Vid2.mp4/frame_0009.jpg: 203 keypoints in 0.0647s\n",
      "Vid3.mp4/frame_0000.jpg: 306 keypoints in 0.0668s\n",
      "Vid3.mp4/frame_0001.jpg: 336 keypoints in 0.0505s\n",
      "Vid3.mp4/frame_0002.jpg: 357 keypoints in 0.0539s\n",
      "Vid3.mp4/frame_0003.jpg: 359 keypoints in 0.0489s\n",
      "Vid3.mp4/frame_0004.jpg: 368 keypoints in 0.0494s\n",
      "Vid3.mp4/frame_0005.jpg: 361 keypoints in 0.0474s\n",
      "Vid3.mp4/frame_0006.jpg: 361 keypoints in 0.0412s\n",
      "Vid3.mp4/frame_0007.jpg: 360 keypoints in 0.0415s\n",
      "Vid3.mp4/frame_0008.jpg: 372 keypoints in 0.0437s\n",
      "Vid3.mp4/frame_0009.jpg: 339 keypoints in 0.0431s\n",
      "Vid4.mp4/frame_0000.jpg: 662 keypoints in 0.0483s\n",
      "Vid4.mp4/frame_0001.jpg: 674 keypoints in 0.0493s\n",
      "Vid4.mp4/frame_0002.jpg: 688 keypoints in 0.0505s\n",
      "Vid4.mp4/frame_0003.jpg: 673 keypoints in 0.0500s\n",
      "Vid4.mp4/frame_0004.jpg: 728 keypoints in 0.0567s\n",
      "Vid4.mp4/frame_0005.jpg: 719 keypoints in 0.0505s\n",
      "Vid4.mp4/frame_0006.jpg: 665 keypoints in 0.0483s\n",
      "Vid4.mp4/frame_0007.jpg: 686 keypoints in 0.0509s\n",
      "Vid4.mp4/frame_0008.jpg: 688 keypoints in 0.0517s\n",
      "Vid4.mp4/frame_0009.jpg: 723 keypoints in 0.0499s\n",
      "Vid5.mp4/frame_0000.jpg: 622 keypoints in 0.0495s\n",
      "Vid5.mp4/frame_0001.jpg: 657 keypoints in 0.0483s\n",
      "Vid5.mp4/frame_0002.jpg: 632 keypoints in 0.0551s\n",
      "Vid5.mp4/frame_0003.jpg: 666 keypoints in 0.0616s\n",
      "Vid5.mp4/frame_0004.jpg: 648 keypoints in 0.0579s\n",
      "Vid5.mp4/frame_0005.jpg: 654 keypoints in 0.0483s\n",
      "Vid5.mp4/frame_0006.jpg: 640 keypoints in 0.0655s\n",
      "Vid5.mp4/frame_0007.jpg: 634 keypoints in 0.0535s\n",
      "Vid5.mp4/frame_0008.jpg: 628 keypoints in 0.0518s\n",
      "Vid5.mp4/frame_0009.jpg: 642 keypoints in 0.0496s\n",
      "Average keypoints: 450.38 | Average Time: 0.07s\n",
      "\n",
      " - - BRISK - -\n",
      "Vid1.mp4/frame_0000.jpg: 355 keypoints in 0.0253s\n",
      "Vid1.mp4/frame_0001.jpg: 347 keypoints in 0.0197s\n",
      "Vid1.mp4/frame_0002.jpg: 333 keypoints in 0.0189s\n",
      "Vid1.mp4/frame_0003.jpg: 363 keypoints in 0.0215s\n",
      "Vid1.mp4/frame_0004.jpg: 362 keypoints in 0.0197s\n",
      "Vid1.mp4/frame_0005.jpg: 366 keypoints in 0.0200s\n",
      "Vid1.mp4/frame_0006.jpg: 369 keypoints in 0.0198s\n",
      "Vid1.mp4/frame_0007.jpg: 374 keypoints in 0.0197s\n",
      "Vid1.mp4/frame_0008.jpg: 386 keypoints in 0.0200s\n",
      "Vid1.mp4/frame_0009.jpg: 381 keypoints in 0.0197s\n",
      "Vid2.mp4/frame_0000.jpg: 422 keypoints in 0.0227s\n",
      "Vid2.mp4/frame_0001.jpg: 387 keypoints in 0.0206s\n",
      "Vid2.mp4/frame_0002.jpg: 356 keypoints in 0.0187s\n",
      "Vid2.mp4/frame_0003.jpg: 387 keypoints in 0.0195s\n",
      "Vid2.mp4/frame_0004.jpg: 381 keypoints in 0.0196s\n",
      "Vid2.mp4/frame_0005.jpg: 379 keypoints in 0.0198s\n",
      "Vid2.mp4/frame_0006.jpg: 375 keypoints in 0.0188s\n",
      "Vid2.mp4/frame_0007.jpg: 397 keypoints in 0.0190s\n",
      "Vid2.mp4/frame_0008.jpg: 414 keypoints in 0.0175s\n",
      "Vid2.mp4/frame_0009.jpg: 374 keypoints in 0.0168s\n",
      "Vid3.mp4/frame_0000.jpg: 469 keypoints in 0.0192s\n",
      "Vid3.mp4/frame_0001.jpg: 436 keypoints in 0.0189s\n",
      "Vid3.mp4/frame_0002.jpg: 414 keypoints in 0.0184s\n",
      "Vid3.mp4/frame_0003.jpg: 446 keypoints in 0.0189s\n",
      "Vid3.mp4/frame_0004.jpg: 439 keypoints in 0.0186s\n",
      "Vid3.mp4/frame_0005.jpg: 457 keypoints in 0.0189s\n",
      "Vid3.mp4/frame_0006.jpg: 461 keypoints in 0.0191s\n",
      "Vid3.mp4/frame_0007.jpg: 459 keypoints in 0.0191s\n",
      "Vid3.mp4/frame_0008.jpg: 467 keypoints in 0.0191s\n",
      "Vid3.mp4/frame_0009.jpg: 480 keypoints in 0.0200s\n",
      "Vid4.mp4/frame_0000.jpg: 829 keypoints in 0.0257s\n",
      "Vid4.mp4/frame_0001.jpg: 860 keypoints in 0.0256s\n",
      "Vid4.mp4/frame_0002.jpg: 787 keypoints in 0.0245s\n",
      "Vid4.mp4/frame_0003.jpg: 826 keypoints in 0.0237s\n",
      "Vid4.mp4/frame_0004.jpg: 830 keypoints in 0.0269s\n",
      "Vid4.mp4/frame_0005.jpg: 856 keypoints in 0.0277s\n",
      "Vid4.mp4/frame_0006.jpg: 862 keypoints in 0.0233s\n",
      "Vid4.mp4/frame_0007.jpg: 860 keypoints in 0.0232s\n",
      "Vid4.mp4/frame_0008.jpg: 853 keypoints in 0.0232s\n",
      "Vid4.mp4/frame_0009.jpg: 858 keypoints in 0.0229s\n",
      "Vid5.mp4/frame_0000.jpg: 650 keypoints in 0.0199s\n",
      "Vid5.mp4/frame_0001.jpg: 584 keypoints in 0.0177s\n",
      "Vid5.mp4/frame_0002.jpg: 588 keypoints in 0.0181s\n",
      "Vid5.mp4/frame_0003.jpg: 593 keypoints in 0.0180s\n",
      "Vid5.mp4/frame_0004.jpg: 618 keypoints in 0.0185s\n",
      "Vid5.mp4/frame_0005.jpg: 600 keypoints in 0.0185s\n",
      "Vid5.mp4/frame_0006.jpg: 650 keypoints in 0.0189s\n",
      "Vid5.mp4/frame_0007.jpg: 620 keypoints in 0.0185s\n",
      "Vid5.mp4/frame_0008.jpg: 610 keypoints in 0.0183s\n",
      "Vid5.mp4/frame_0009.jpg: 625 keypoints in 0.0186s\n",
      "Average keypoints: 531.90 | Average Time: 0.02s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#feature detection using ORB, SIFT, and BRISK\n",
    "def load_images_from_all_videos(base_folder, max_images_per_video=10):\n",
    "    all_images = []\n",
    "    video_folders = sorted(os.listdir(base_folder))\n",
    "\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "\n",
    "    for video_folder in video_folders:\n",
    "        full_path = os.path.join(base_folder, video_folder)\n",
    "        if not os.path.isdir(full_path):\n",
    "            continue  # skip non-folder entries\n",
    "\n",
    "        image_filenames = sorted(os.listdir(full_path))\n",
    "        image_files = [f for f in image_filenames if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "\n",
    "        for filename in image_files[:max_images_per_video]:\n",
    "            img_path = os.path.join(full_path, filename)\n",
    "            img_color = cv2.imread(img_path)\n",
    "            if img_color is None:\n",
    "                print(f\"Warning: Couldn't read {img_path}\")\n",
    "                continue\n",
    "            img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "            all_images.append((video_folder + \"/\" + filename, img_color, img_gray))\n",
    "\n",
    "    return all_images\n",
    "\n",
    "#detect features using ORB, SIFT, and BRISK\n",
    "def detect_features(detector, images, use_gray=True):\n",
    "    results = []\n",
    "    for filename, img_color, img_gray in images:\n",
    "        img = img_gray if use_gray else img_color\n",
    "        start_time = time.time()\n",
    "        keypoints, descriptors = detector.detectAndCompute(img, None)\n",
    "        time_taken = time.time() - start_time\n",
    "        results.append({\n",
    "            'filename': filename,\n",
    "            'image': img_color,\n",
    "            'keypoints': keypoints,\n",
    "            'descriptors': descriptors,\n",
    "            'time': time_taken\n",
    "        })\n",
    "    return results\n",
    "\n",
    "#draw keypoints on images\n",
    "def draw_keypoints(results, alg_name, output_dir=\"output_keypoints\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for res in results:\n",
    "        img_with_kp = cv2.drawKeypoints(res['image'], res['keypoints'], None, color=(0, 255, 0))\n",
    "        out_path = os.path.join(output_dir, f\"{alg_name}_{res['filename'].replace('/', '_')}\")\n",
    "        cv2.imwrite(out_path, img_with_kp)\n",
    "\n",
    "#analyze results\n",
    "def analysis(results, alg_name):\n",
    "    print(f\"\\n - - {alg_name} - -\")\n",
    "    total_kps = 0\n",
    "    total_time = 0\n",
    "\n",
    "    #print summary of results\n",
    "    for res in results:\n",
    "        print(f\"{res['filename']}: {len(res['keypoints'])} keypoints in {res['time']:.4f}s\")\n",
    "        total_kps += len(res['keypoints'])\n",
    "        total_time += res['time']\n",
    "    if len(results) > 0:\n",
    "        avg_kps = total_kps / len(results)\n",
    "        avg_time = total_time / len(results)\n",
    "        print(f\"Average keypoints: {avg_kps:.2f} | Average Time: {avg_time:.2f}s\")\n",
    "    else:\n",
    "        print(\"No images were processed.\")\n",
    "\n",
    "frame_dir = \"frames\"  #path to frames\n",
    "images = load_images_from_all_videos(frame_dir, max_images_per_video=10)\n",
    "\n",
    "if not images:\n",
    "    print(\"No images found in any of the video subfolders.\")\n",
    "    exit()\n",
    "\n",
    "#initialize detectors\n",
    "orb = cv2.ORB_create(nfeatures=1000)\n",
    "sift = cv2.SIFT_create()\n",
    "brisk = cv2.BRISK_create()\n",
    "\n",
    "#detect features\n",
    "orb_results = detect_features(orb, images)\n",
    "sift_results = detect_features(sift, images)\n",
    "brisk_results = detect_features(brisk, images)\n",
    "\n",
    "#save keypoint visualizations\n",
    "if not os.path.exists(\"output_keypoints\"): # Exists so no need to save\n",
    "    draw_keypoints(orb_results, \"ORB\")\n",
    "    draw_keypoints(sift_results, \"SIFT\")\n",
    "    draw_keypoints(brisk_results, \"BRISK\")\n",
    "\n",
    "#print comparison summary\n",
    "analysis(orb_results, \"ORB\")\n",
    "analysis(sift_results, \"SIFT\")\n",
    "analysis(brisk_results, \"BRISK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13b070",
   "metadata": {},
   "source": [
    "# 4/5. Feature Matching and Outlier Rejection + Fundamental Matrix Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce227bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing pair: Vid1.mp4/frame_0000.jpg & Vid1.mp4/frame_0001.jpg\n",
      "Total matches before RANSAC: 241\n",
      "Matches after RANSAC: 231\n",
      "\n",
      "Processing pair: Vid1.mp4/frame_0001.jpg & Vid1.mp4/frame_0002.jpg\n",
      "Total matches before RANSAC: 230\n",
      "Matches after RANSAC: 226\n",
      "\n",
      "Processing pair: Vid1.mp4/frame_0002.jpg & Vid1.mp4/frame_0003.jpg\n",
      "Total matches before RANSAC: 247\n",
      "Matches after RANSAC: 241\n",
      "\n",
      "Processing pair: Vid2.mp4/frame_0000.jpg & Vid2.mp4/frame_0001.jpg\n",
      "Total matches before RANSAC: 154\n",
      "Matches after RANSAC: 150\n",
      "\n",
      "Processing pair: Vid2.mp4/frame_0001.jpg & Vid2.mp4/frame_0002.jpg\n",
      "Total matches before RANSAC: 156\n",
      "Matches after RANSAC: 151\n",
      "\n",
      "Processing pair: Vid2.mp4/frame_0002.jpg & Vid2.mp4/frame_0003.jpg\n",
      "Total matches before RANSAC: 158\n",
      "Matches after RANSAC: 152\n",
      "\n",
      "Processing pair: Vid3.mp4/frame_0000.jpg & Vid3.mp4/frame_0001.jpg\n",
      "Total matches before RANSAC: 246\n",
      "Matches after RANSAC: 243\n",
      "\n",
      "Processing pair: Vid3.mp4/frame_0001.jpg & Vid3.mp4/frame_0002.jpg\n",
      "Total matches before RANSAC: 262\n",
      "Matches after RANSAC: 252\n",
      "\n",
      "Processing pair: Vid3.mp4/frame_0002.jpg & Vid3.mp4/frame_0003.jpg\n",
      "Total matches before RANSAC: 258\n",
      "Matches after RANSAC: 248\n",
      "\n",
      "Processing pair: Vid4.mp4/frame_0000.jpg & Vid4.mp4/frame_0001.jpg\n",
      "Total matches before RANSAC: 439\n",
      "Matches after RANSAC: 436\n",
      "\n",
      "Processing pair: Vid4.mp4/frame_0001.jpg & Vid4.mp4/frame_0002.jpg\n",
      "Total matches before RANSAC: 422\n",
      "Matches after RANSAC: 410\n",
      "\n",
      "Processing pair: Vid4.mp4/frame_0002.jpg & Vid4.mp4/frame_0003.jpg\n",
      "Total matches before RANSAC: 424\n",
      "Matches after RANSAC: 415\n",
      "\n",
      "Processing pair: Vid5.mp4/frame_0000.jpg & Vid5.mp4/frame_0001.jpg\n",
      "Total matches before RANSAC: 443\n",
      "Matches after RANSAC: 437\n",
      "\n",
      "Processing pair: Vid5.mp4/frame_0001.jpg & Vid5.mp4/frame_0002.jpg\n",
      "Total matches before RANSAC: 420\n",
      "Matches after RANSAC: 412\n",
      "\n",
      "Processing pair: Vid5.mp4/frame_0002.jpg & Vid5.mp4/frame_0003.jpg\n",
      "Total matches before RANSAC: 421\n",
      "Matches after RANSAC: 417\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#load images from all videos\n",
    "def load_image_pairs(base_folder, step=1, max_pairs_per_video=3):\n",
    "    pairs = []\n",
    "    video_folders = sorted(os.listdir(base_folder))\n",
    "\n",
    "    #filter out non-directory entries\n",
    "    for video_folder in video_folders:\n",
    "        folder_path = os.path.join(base_folder, video_folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        filenames = sorted([f for f in os.listdir(folder_path) if f.endswith((\".jpg\", \".jpeg\", \".png\"))])\n",
    "        num_pairs = min(len(filenames) - step, max_pairs_per_video)\n",
    "\n",
    "        for i in range(num_pairs):\n",
    "            img1_path = os.path.join(folder_path, filenames[i])\n",
    "            img2_path = os.path.join(folder_path, filenames[i + step])\n",
    "\n",
    "            img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if img1 is not None and img2 is not None:\n",
    "                pairs.append((f\"{video_folder}/{filenames[i]}\", f\"{video_folder}/{filenames[i+step]}\", img1, img2))\n",
    "    return pairs\n",
    "\n",
    "#get feature detector\n",
    "def get_detector(name=\"SIFT\"):\n",
    "    if name == \"ORB\":\n",
    "        return cv2.ORB_create(nfeatures=1000)\n",
    "    elif name == \"BRISK\":\n",
    "        return cv2.BRISK_create()\n",
    "    else:\n",
    "        return cv2.SIFT_create()\n",
    "\n",
    "#get matcher based on descriptor type\n",
    "def get_matcher(desc_type):\n",
    "    if desc_type == \"float\":\n",
    "        index_params = dict(algorithm=1, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "        return cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    else:\n",
    "        return cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "#match features between two images\n",
    "def match_features(detector, img1, img2):\n",
    "    kp1, des1 = detector.detectAndCompute(img1, None)\n",
    "    kp2, des2 = detector.detectAndCompute(img2, None)\n",
    "\n",
    "    if des1 is None or des2 is None:\n",
    "        return kp1, kp2, []\n",
    "\n",
    "    #check descriptor type\n",
    "    desc_type = \"float\" if des1.dtype == np.float32 else \"binary\"\n",
    "    matcher = get_matcher(desc_type)\n",
    "\n",
    "    if desc_type == \"float\":\n",
    "        matches = matcher.knnMatch(des1, des2, k=2)\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good_matches.append(m)\n",
    "    else:\n",
    "        matches = matcher.match(des1, des2)\n",
    "        good_matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    return kp1, kp2, good_matches\n",
    "\n",
    "#ransac filter to remove outliers\n",
    "def ransac_filter(kp1, kp2, matches):\n",
    "    if len(matches) < 8:\n",
    "        return [], None\n",
    "\n",
    "    #extract location of good matches\n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
    "\n",
    "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.RANSAC)\n",
    "    inliers = [m for i, m in enumerate(matches) if mask[i]]\n",
    "\n",
    "    return inliers, F\n",
    "\n",
    "#draw matches between two images\n",
    "def draw_matches(img1, kp1, img2, kp2, matches, title, out_folder=\"output_matches\", filename_prefix=\"match\"):\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.makedirs(out_folder)\n",
    "\n",
    "    #draw matches\n",
    "    matched_img = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(matched_img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "    #save figure with title in filename\n",
    "    safe_title = title.replace(\" \", \"_\").lower()\n",
    "    out_path = os.path.join(out_folder, f\"{filename_prefix}_{safe_title}.png\")\n",
    "    plt.savefig(out_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "#set parameters\n",
    "frame_dir = \"frames\"\n",
    "detector_name = \"SIFT\"\n",
    "detector = get_detector(detector_name)\n",
    "\n",
    "pairs = load_image_pairs(frame_dir, step=1, max_pairs_per_video=3)\n",
    "\n",
    "#check if pairs are loaded\n",
    "for fname1, fname2, img1, img2 in pairs:\n",
    "    print(f\"\\nProcessing pair: {fname1} & {fname2}\")\n",
    "    kp1, kp2, matches = match_features(detector, img1, img2)\n",
    "\n",
    "    print(f\"Total matches before RANSAC: {len(matches)}\")\n",
    "\n",
    "    draw_matches(img1, kp1, img2, kp2, matches, title=\"Before RANSAC\", filename_prefix=f\"{fname1.replace('/', '_')}_vs_{fname2.replace('/', '_')}\")\n",
    "\n",
    "    inliers, F = ransac_filter(kp1, kp2, matches)\n",
    "    print(f\"Matches after RANSAC: {len(inliers)}\")\n",
    "    draw_matches(img1, kp1, img2, kp2, inliers, title=\"After RANSAC\", filename_prefix=f\"{fname1.replace('/', '_')}_vs_{fname2.replace('/', '_')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4233568b",
   "metadata": {},
   "source": [
    "As required by the assignment, this section explains the underlying calculations involved in computing the fundamental matrix and clarifies the distinction between calibrated and uncalibrated cameras.\n",
    "\n",
    "#### 5a. Understanding Underlying Calculations for Fundamental Matrix Computation\n",
    "\n",
    "When computing the fundamental matrix ($F$) using a function like OpenCV's `cv.findFundamentalMat()`, the process relies on the epipolar constraint, which states that for any pair of corresponding points $p_1$ in the first image and $p_2$ in the second image, the following relationship holds:\n",
    "\n",
    "$$p_2^T F p_1 = 0$$\n",
    "\n",
    "Here, $p_1$ and $p_2$ are the homogeneous coordinates of the points. The fundamental matrix is a $3 \\times 3$ matrix that encapsulates the epipolar geometry between the two uncalibrated views.\n",
    "\n",
    "The fundamental matrix has 9 elements but is determined up to a scale factor, giving 8 degrees of freedom. Additionally, it must satisfy the rank constraint $det(F) = 0$.\n",
    "\n",
    "A common method for estimating the fundamental matrix is the **Eight-Point Algorithm**. This algorithm uses at least 8 pairs of corresponding points to set up a system of linear equations in the elements of $F$. Each corresponding point pair $(p_{1i}, p_{2i})$ contributes one linear equation based on the epipolar constraint. If we stack the elements of $F$ into a vector $f$, we get a system of equations $Af = 0$, where $A$ is a matrix derived from the point coordinates. This system can be solved for $f$ (and thus $F$) using methods like Singular Value Decomposition (SVD).\n",
    "\n",
    "The linear estimate of $F$ from the 8-point algorithm may not satisfy the rank-2 constraint. To enforce this, SVD is typically applied to the estimated $F = U \\Sigma V^T$. We then set the smallest singular value in $\\Sigma$ to zero to produce $\\Sigma'$, resulting in the rank-2 fundamental matrix $F' = U \\Sigma' V^T$.\n",
    "\n",
    "In the presence of outliers (incorrect matches), a robust estimation method like **RANSAC (Random Sample Consensus)** is employed. When you use `cv.findFundamentalMat()` with the `cv2.RANSAC` method, OpenCV is internally implementing a RANSAC-based approach. RANSAC iteratively:\n",
    "1.  Selects a minimal set of 8 point correspondences.\n",
    "2.  Computes a candidate fundamental matrix using these points.\n",
    "3.  Counts how many of the *remaining* points are consistent with this matrix (inliers).\n",
    "4.  Repeats this process many times and chooses the matrix with the largest number of inliers.\n",
    "5.  Optionally, re-estimates the matrix using all identified inliers.\n",
    "\n",
    "This robust estimation is crucial for obtaining an accurate fundamental matrix from noisy real-world data.\n",
    "\n",
    "#### 5b. Difference Between Calibrated and Uncalibrated Cameras\n",
    "\n",
    "The choice of computing the essential matrix ($E$) or the fundamental matrix ($F$) depends on whether your cameras are calibrated.\n",
    "\n",
    "* **Uncalibrated Cameras:**\n",
    "    * **Definition:** Cameras for which the intrinsic parameters (focal length, principal point, distortion coefficients) are **unknown**.\n",
    "    * **Matrix:** The **Fundamental Matrix ($F$)** is used.\n",
    "    * **Coordinates:** $F$ relates corresponding points in **image coordinates (pixels)**.\n",
    "    * **Purpose:** Describes the epipolar geometry (relationship between points and epipolar lines) in the image plane. It can be used to verify point correspondences and find epipolar lines.\n",
    "    * **Limitation:** Without knowing the intrinsic parameters, $F$ does not encode metric information about the scene or the cameras' 3D motion.\n",
    "\n",
    "* **Calibrated Cameras:**\n",
    "    * **Definition:** Cameras for which the intrinsic parameters are **known** (usually determined through a camera calibration procedure).\n",
    "    * **Matrix:** The **Essential Matrix ($E$)** is used.\n",
    "    * **Coordinates:** $E$ relates corresponding points in **normalized image coordinates**. These coordinates are obtained by removing the effect of intrinsic parameters (e.g., by multiplying image coordinates by the inverse of the camera intrinsic matrix, $K^{-1}$).\n",
    "    * **Relationship:** The essential matrix is related to the fundamental matrix by the camera intrinsic matrices $K_1$ and $K_2$: $E = K_2^T F K_1$.\n",
    "    * **Purpose:** Describes the epipolar geometry in a normalized coordinate system and crucially encodes the **relative rotation and translation** between the two camera views.\n",
    "    * **Advantage:** Knowing the intrinsic parameters and having the essential matrix allows for the recovery of the camera's relative 3D pose and enables metric 3D reconstruction of the scene.\n",
    "\n",
    "In the context of this assignment, the videos were taken using an uncalibrated mobile phone camera. Therefore the fundamental matrix was computed and not the essential matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b83e14",
   "metadata": {},
   "source": [
    "6. Camera Position Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39cef311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Placeholder Camera Matrix:\n",
      "[[4.50e+03 0.00e+00 2.39e+02]\n",
      " [0.00e+00 4.50e+03 4.25e+02]\n",
      " [0.00e+00 0.00e+00 1.00e+00]]\n",
      "\n",
      "--- Camera Pose Estimation Results ---\n",
      "Number of points successfully reconstructed in front of both cameras: 0\n",
      "\n",
      "Estimated Rotation Matrix (R):\n",
      "[[ 0.99840873 -0.00327113 -0.05629657]\n",
      " [ 0.00609101  0.99873107  0.04999145]\n",
      " [ 0.0560616  -0.0502548   0.99716175]]\n",
      "\n",
      "Estimated Translation Vector (t):\n",
      "[[-0.66374949]\n",
      " [-0.74795118]\n",
      " [-0.00237406]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pixel_focal_length = 4500\n",
    "image_width = 478\n",
    "image_height = 850\n",
    "\n",
    "# Principal point assumed at the image center\n",
    "principal_point_x = image_width / 2\n",
    "principal_point_y = image_height / 2\n",
    "\n",
    "camera_matrix = np.array([[pixel_focal_length, 0, principal_point_x], [0, pixel_focal_length, principal_point_y], [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "print(\"Using Placeholder Camera Matrix:\")\n",
    "print(camera_matrix)\n",
    "\n",
    "\n",
    "# Extract points from inlier matches\n",
    "pts1 = np.float32([kp1[m.queryIdx].pt for m in inliers]).reshape(-1, 1, 2)\n",
    "pts2 = np.float32([kp2[m.trainIdx].pt for m in inliers]).reshape(-1, 1, 2)\n",
    "\n",
    "\n",
    "# Estimate camera pose using recoverPose\n",
    "# Note: Using F with a placeholder K provides scaled translation.\n",
    "ret, R, t, mask = cv2.recoverPose(F, pts1, pts2, camera_matrix)\n",
    "\n",
    "print(\"\\n--- Camera Pose Estimation Results ---\")\n",
    "print(f\"Number of points successfully reconstructed in front of both cameras: {ret}\")\n",
    "print(\"\\nEstimated Rotation Matrix (R):\")\n",
    "print(R)\n",
    "print(\"\\nEstimated Translation Vector (t):\")\n",
    "print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
