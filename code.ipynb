{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c9b209",
   "metadata": {},
   "source": [
    "# 2. Frame Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53cc4e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames had already been extracted, skipping...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_dir, frame_rate=1):\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not video.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "    \n",
    "    print(f\"Video FPS: {fps}\")\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    print(f\"Duration: {duration:.2f} seconds\")\n",
    "    \n",
    "    # Initialize frame counter\n",
    "    count = 0\n",
    "    frame_count = 0\n",
    "    \n",
    "    # Read until video is completed\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        # Break the loop if we have reached the end of the video\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Save frame at the specified interval\n",
    "        if count % 1 == 0:\n",
    "            frame_filename = os.path.join(output_dir, f\"frame_{frame_count:04d}.jpg\")\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            print(f\"Extracted: {frame_filename}\")\n",
    "            frame_count += 1\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    # Release the video capture object\n",
    "    video.release()\n",
    "    \n",
    "    print(f\"Extraction complete. {frame_count} frames extracted to {output_dir}\")\n",
    "\n",
    "def get_file_paths():\n",
    "    file_paths = []\n",
    "\n",
    "    for root, dirs, files in os.walk(\"videos\"):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path)\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "if not os.path.isdir('frames'): # If it exists, it was done already so do not run\n",
    "    file_paths = get_file_paths()\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        extract_frames(file_path, os.path.join(\"frames\", os.path.basename(file_path)))\n",
    "else :\n",
    "    print(\"Frames had already been extracted, skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6606cc",
   "metadata": {},
   "source": [
    "# 3. Feature Detection and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4367854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#feature detection using ORB, SIFT, and BRISK\n",
    "def load_images_from_all_videos(base_folder, max_images_per_video=10):\n",
    "    all_images = []\n",
    "    video_folders = sorted(os.listdir(base_folder))\n",
    "\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "\n",
    "    for video_folder in video_folders:\n",
    "        full_path = os.path.join(base_folder, video_folder)\n",
    "        if not os.path.isdir(full_path):\n",
    "            continue  # skip non-folder entries\n",
    "\n",
    "        image_filenames = sorted(os.listdir(full_path))\n",
    "        image_files = [f for f in image_filenames if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "\n",
    "        for filename in image_files[:max_images_per_video]:\n",
    "            img_path = os.path.join(full_path, filename)\n",
    "            img_color = cv2.imread(img_path)\n",
    "            if img_color is None:\n",
    "                print(f\"Warning: Couldn't read {img_path}\")\n",
    "                continue\n",
    "            img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "            all_images.append((video_folder + \"/\" + filename, img_color, img_gray))\n",
    "\n",
    "    return all_images\n",
    "\n",
    "#detect features using ORB, SIFT, and BRISK\n",
    "def detect_features(detector, images, use_gray=True):\n",
    "    results = []\n",
    "    for filename, img_color, img_gray in images:\n",
    "        img = img_gray if use_gray else img_color\n",
    "        start_time = time.time()\n",
    "        keypoints, descriptors = detector.detectAndCompute(img, None)\n",
    "        time_taken = time.time() - start_time\n",
    "        results.append({\n",
    "            'filename': filename,\n",
    "            'image': img_color,\n",
    "            'keypoints': keypoints,\n",
    "            'descriptors': descriptors,\n",
    "            'time': time_taken\n",
    "        })\n",
    "    return results\n",
    "\n",
    "#draw keypoints on images\n",
    "def draw_keypoints(results, alg_name, output_dir=\"output_keypoints\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for res in results:\n",
    "        img_with_kp = cv2.drawKeypoints(res['image'], res['keypoints'], None, color=(0, 255, 0))\n",
    "        out_path = os.path.join(output_dir, f\"{alg_name}_{res['filename'].replace('/', '_')}\")\n",
    "        cv2.imwrite(out_path, img_with_kp)\n",
    "\n",
    "#analyze results\n",
    "def analysis(results, alg_name):\n",
    "    print(f\"\\n - - {alg_name} - -\")\n",
    "    total_kps = 0\n",
    "    total_time = 0\n",
    "\n",
    "    #print summary of results\n",
    "    for res in results:\n",
    "        print(f\"{res['filename']}: {len(res['keypoints'])} keypoints in {res['time']:.4f}s\")\n",
    "        total_kps += len(res['keypoints'])\n",
    "        total_time += res['time']\n",
    "    if len(results) > 0:\n",
    "        avg_kps = total_kps / len(results)\n",
    "        avg_time = total_time / len(results)\n",
    "        print(f\"Average keypoints: {avg_kps:.2f} | Average Time: {avg_time:.2f}s\")\n",
    "    else:\n",
    "        print(\"No images were processed.\")\n",
    "\n",
    "frame_dir = \"frames\"  #path to frames\n",
    "images = load_images_from_all_videos(frame_dir, max_images_per_video=10)\n",
    "\n",
    "if not images:\n",
    "    print(\"No images found in any of the video subfolders.\")\n",
    "    exit()\n",
    "\n",
    "#initialize detectors\n",
    "orb = cv2.ORB_create(nfeatures=1000)\n",
    "sift = cv2.SIFT_create()\n",
    "brisk = cv2.BRISK_create()\n",
    "\n",
    "#detect features\n",
    "orb_results = detect_features(orb, images)\n",
    "sift_results = detect_features(sift, images)\n",
    "brisk_results = detect_features(brisk, images)\n",
    "\n",
    "#save keypoint visualizations\n",
    "if not os.path.exists(\"output_keypoints\"): # Exists so no need to save\n",
    "    draw_keypoints(orb_results, \"ORB\")\n",
    "    draw_keypoints(sift_results, \"SIFT\")\n",
    "    draw_keypoints(brisk_results, \"BRISK\")\n",
    "\n",
    "#print comparison summary\n",
    "analysis(orb_results, \"ORB\")\n",
    "analysis(sift_results, \"SIFT\")\n",
    "analysis(brisk_results, \"BRISK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13b070",
   "metadata": {},
   "source": [
    "# 4/5. Feature Matching and Outlier Rejection + Fundamental Matrix Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce227bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#load images from all videos\n",
    "def load_image_pairs(base_folder, step=1, max_pairs_per_video=3):\n",
    "    pairs = []\n",
    "    video_folders = sorted(os.listdir(base_folder))\n",
    "\n",
    "    #filter out non-directory entries\n",
    "    for video_folder in video_folders:\n",
    "        folder_path = os.path.join(base_folder, video_folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        filenames = sorted([f for f in os.listdir(folder_path) if f.endswith((\".jpg\", \".jpeg\", \".png\"))])\n",
    "        num_pairs = min(len(filenames) - step, max_pairs_per_video)\n",
    "\n",
    "        for i in range(num_pairs):\n",
    "            img1_path = os.path.join(folder_path, filenames[i])\n",
    "            img2_path = os.path.join(folder_path, filenames[i + step])\n",
    "\n",
    "            img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if img1 is not None and img2 is not None:\n",
    "                pairs.append((f\"{video_folder}/{filenames[i]}\", f\"{video_folder}/{filenames[i+step]}\", img1, img2))\n",
    "    return pairs\n",
    "\n",
    "#get feature detector\n",
    "def get_detector(name=\"SIFT\"):\n",
    "    if name == \"ORB\":\n",
    "        return cv2.ORB_create(nfeatures=1000)\n",
    "    elif name == \"BRISK\":\n",
    "        return cv2.BRISK_create()\n",
    "    else:\n",
    "        return cv2.SIFT_create()\n",
    "\n",
    "#get matcher based on descriptor type\n",
    "def get_matcher(desc_type):\n",
    "    if desc_type == \"float\":\n",
    "        index_params = dict(algorithm=1, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "        return cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    else:\n",
    "        return cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "#match features between two images\n",
    "def match_features(detector, img1, img2):\n",
    "    kp1, des1 = detector.detectAndCompute(img1, None)\n",
    "    kp2, des2 = detector.detectAndCompute(img2, None)\n",
    "\n",
    "    if des1 is None or des2 is None:\n",
    "        return kp1, kp2, []\n",
    "\n",
    "    #check descriptor type\n",
    "    desc_type = \"float\" if des1.dtype == np.float32 else \"binary\"\n",
    "    matcher = get_matcher(desc_type)\n",
    "\n",
    "    if desc_type == \"float\":\n",
    "        matches = matcher.knnMatch(des1, des2, k=2)\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good_matches.append(m)\n",
    "    else:\n",
    "        matches = matcher.match(des1, des2)\n",
    "        good_matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    return kp1, kp2, good_matches\n",
    "\n",
    "#ransac filter to remove outliers\n",
    "def ransac_filter(kp1, kp2, matches):\n",
    "    if len(matches) < 8:\n",
    "        return [], None\n",
    "\n",
    "    #extract location of good matches\n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
    "\n",
    "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.RANSAC)\n",
    "    inliers = [m for i, m in enumerate(matches) if mask[i]]\n",
    "\n",
    "    return inliers, F\n",
    "\n",
    "#draw matches between two images\n",
    "def draw_matches(img1, kp1, img2, kp2, matches, title, out_folder=\"output_matches\", filename_prefix=\"match\"):\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.makedirs(out_folder)\n",
    "\n",
    "    #draw matches\n",
    "    matched_img = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(matched_img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "    #save figure with title in filename\n",
    "    safe_title = title.replace(\" \", \"_\").lower()\n",
    "    out_path = os.path.join(out_folder, f\"{filename_prefix}_{safe_title}.png\")\n",
    "    plt.savefig(out_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    #set parameters\n",
    "    frame_dir = \"frames\"\n",
    "    detector_name = \"SIFT\"\n",
    "    detector = get_detector(detector_name)\n",
    "\n",
    "    pairs = load_image_pairs(frame_dir, step=1, max_pairs_per_video=3)\n",
    "\n",
    "    #check if pairs are loaded\n",
    "    for fname1, fname2, img1, img2 in pairs:\n",
    "        print(f\"\\nProcessing pair: {fname1} & {fname2}\")\n",
    "        kp1, kp2, matches = match_features(detector, img1, img2)\n",
    "\n",
    "        print(f\"Total matches before RANSAC: {len(matches)}\")\n",
    "        draw_matches(img1, kp1, img2, kp2, matches, title=\"Before RANSAC\", filename_prefix=f\"{fname1.replace('/', '_')}_vs_{fname2.replace('/', '_')}\")\n",
    "\n",
    "        inliers, F = ransac_filter(kp1, kp2, matches)\n",
    "        print(f\"Matches after RANSAC: {len(inliers)}\")\n",
    "        draw_matches(img1, kp1, img2, kp2, inliers, title=\"After RANSAC\", filename_prefix=f\"{fname1.replace('/', '_')}_vs_{fname2.replace('/', '_')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
